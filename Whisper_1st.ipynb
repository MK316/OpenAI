{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNCaTkWwY5uO09l2J8hfDx4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/OpenAI/blob/main/Whisper_1st.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Whisper - 1st practice (22.12.20)\n",
        "\n",
        "[Video tutorial](https://www.youtube.com/watch?v=wrSelk44_Js)\n",
        "\n",
        "[Whisper license](https://github.com/openai/whisper/blob/main/LICENSE) - Copyright (c) 2022 OpenAI\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"),..."
      ],
      "metadata": {
        "id": "ta_H1AqoCdQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video tutorial (Play if you want)"
      ],
      "metadata": {
        "id": "vKkMerYWCuiV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxnPzg74CXlT"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from IPython.display import YouTubeVideo, display\n",
        "video = YouTubeVideo(\"wrSelk44_Js\", width=500)\n",
        "display(video)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "github.com/openai/whisper"
      ],
      "metadata": {
        "id": "7ZvUPmAsDJN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/openai/whisper.git "
      ],
      "metadata": {
        "id": "1xku6V5oDKA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1] Base model access"
      ],
      "metadata": {
        "id": "laXNqxU-ECmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload speech file from your computer\n",
        "\n",
        "[sample speech short - rainbow passage](https://github.com/MK316/OpenAI/blob/main/audiodata/sample02.wav)"
      ],
      "metadata": {
        "id": "TrIKxVDqEntt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "B-o4ZHmKDlFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model('base.en')\n",
        "result = model.transcribe(\"sample02.wav\", language=\"en\",fp16=False)\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "5bKpmuHGErrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [2] Transcribing Korean audio"
      ],
      "metadata": {
        "id": "9mwQ97osGD1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Korean speech file using gTTS"
      ],
      "metadata": {
        "id": "_Qh8P1j1GDR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gTTS"
      ],
      "metadata": {
        "id": "cArdnfU4GOHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 🚩 Making a function { tts ( _text_to_say_) }:\n",
        "def tts(text):\n",
        "\n",
        "  !pip install gTTS\n",
        "  from gtts import gTTS\n",
        "  from IPython.display import Audio\n",
        "\n",
        "  text_to_say = text\n",
        "\n",
        "# Step ⓵ Language to choose:\n",
        "  language_to_choose = \"ko\" #@param [\"en\", \"fr\",\"ko\",'es']\n",
        "  # lang = language_to_choose\n",
        "  print(\"Play language accent: %s\"%language_to_choose)\n",
        "  language = language_to_choose\n",
        "\n",
        "# gTTS\n",
        "  gtts_object = gTTS(text = text_to_say,\n",
        "                     lang = language,\n",
        "                    slow = False)\n",
        "  \n",
        "# #@markdown Step ③: Create the audio file (.wav) to play:\n",
        "  gtts_object.save(\"sample.wav\")\n",
        "\n",
        "# # Output\n",
        "  return Audio(\"sample.wav\")\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mlMeZGApGlc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* text1: \"밤이 늦었습니다. 오늘도 재미있는 코딩을 배우는 중입니다. 한국어라서 잘 구현될지 모르겠네요.\"\n",
        "\n",
        "* text2: \"착하지만 가난한 동생과 욕심 많은 형의 이야기인 흥부놀부전. 내용을 간단히 소개하자면 흥부는 온갖 어려움 속에서도 착한 마음을 잃지 않았지만, 놀부는 끝까지 욕심을 부리다가 벌을 받게 된다. 착한 흥부는 벌을 받은 형을 버리지 않고 도와주고, 뒷날 흥부는 착한 사람을 대표하는 이름이, 놀부는 욕심 많은 사람을 대표하는 이름이 되었다. 나쁜 마음씨를 갖고 살면 벌을 받고, 착하게 살면 복을 받는다는 전형적인 전래동화의 교훈을 담고 있다.\""
      ],
      "metadata": {
        "id": "nVAwVHP7NtAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 🚩 Type text to say\n",
        "print('Type texts to create audio:')\n",
        "txt = input()\n",
        "tts(txt)"
      ],
      "metadata": {
        "id": "vxobpRf-G2MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Recording was done manually on Praat by playing the generated gTTS audio (ko).\n",
        "\n",
        "[sample audio](https://github.com/MK316/OpenAI/blob/main/audiodata/sample_ko_01.wav)\n",
        "\n",
        "[text2 audio](https://github.com/MK316/OpenAI/blob/main/audiodata/sample_k_shortstory_ttsvoice.wav)  \n",
        "\n",
        "* _Note_: the sentence was copied to see whether the error comes from the boundary of audio files."
      ],
      "metadata": {
        "id": "Jwfy6lUIHu5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model('base')\n",
        "result = model.transcribe('sample_ko_01.wav', language=\"ko\", fp16=False)\n",
        "print(result['text'])"
      ],
      "metadata": {
        "id": "YhU6d5TNIHI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"small\")\n",
        "result = model.transcribe('sample_ko_01.wav', language=\"ko\",task = 'translate', fp16=False)\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "bH4Hi7I2PXGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample 2: short story\n",
        "\n",
        "* Text: \"착하지만 가난한 동생과 욕심 많은 형의 이야기인 흥부놀부전. 내용을 간단히 소개하자면 흥부는 온갖 어려움 속에서도 착한 마음을 잃지 않았지만, 놀부는 끝까지 욕심을 부리다가 벌을 받게 된다. 착한 흥부는 벌을 받은 형을 버리지 않고 도와주고, 뒷날 흥부는 착한 사람을 대표하는 이름이, 놀부는 욕심 많은 사람을 대표하는 이름이 되었다. 나쁜 마음씨를 갖고 살면 벌을 받고, 착하게 살면 복을 받는다는 전형적인 전래동화의 교훈을 담고 있다.\"  \n",
        "[online source](https://m.post.naver.com/viewer/postView.naver?volumeNo=9154443&memberNo=15460571)  \n",
        "[audiofile info](https://raw.githubusercontent.com/MK316/OpenAI/main/audiodata/audiofile_info.md)"
      ],
      "metadata": {
        "id": "O44t25LXKf3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "text2 audio (by human, female)"
      ],
      "metadata": {
        "id": "qQOAawR0OvL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model('base')\n",
        "result = model.transcribe('sample_k_shortstory.wav', language=\"ko\", fp16=False)\n",
        "print(result['text'])"
      ],
      "metadata": {
        "id": "txEF7oomKtI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "translate task"
      ],
      "metadata": {
        "id": "5Eu1-kGOP3RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"small\")\n",
        "result = model.transcribe('sample_k_shortstory.wav', language=\"ko\",task = 'translate', fp16=False)\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "73u10ICCP2jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "text2 audio (by gTTS, male)"
      ],
      "metadata": {
        "id": "sqZz_S-nOyuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model('base')\n",
        "result = model.transcribe('sample_k_shortstory_ttsvoice.wav', language=\"ko\", fp16=False)\n",
        "print(result['text'])"
      ],
      "metadata": {
        "id": "EbnhARY4OuDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [3] Low level model access"
      ],
      "metadata": {
        "id": "SJz-163CNLfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model('small')\n",
        "\n",
        "audio = whisper.load_audio('sample_ko_01.wav')\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "# make log-mel spectrogram and move to the same device as the model.\n",
        "\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n"
      ],
      "metadata": {
        "id": "cB8I4NHOMWyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Language detection:\n",
        "\n",
        "[Trained data](https://raw.githubusercontent.com/openai/whisper/main/language-breakdown.svg)"
      ],
      "metadata": {
        "id": "lKKtHzh2Qpje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# detect the spoken language\n",
        "\n",
        "_, probs = model.detect_language(mel)\n",
        "lang = max(probs, key = probs.get)\n",
        "prob = \"{0:.0%}\".format(max(probs.values()))\n",
        "\n",
        "# print language that scored teh hightest liklihood\n",
        "\n",
        "print(f'Detected language (and probability): {lang}', f'({prob})')"
      ],
      "metadata": {
        "id": "cruy9sMqQooB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2] Korean to English translation (Text1 is excellent but the result of Text2 is very poor.)"
      ],
      "metadata": {
        "id": "PXCwFqiuRo2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decode the audio\n",
        "\n",
        "options = whisper.DecodingOptions(language=\"ko\", task = 'translate')\n",
        "result = whisper.decode(model, mel, options)\n",
        "\n",
        "# print the recognized text\n",
        "print(result.text)"
      ],
      "metadata": {
        "id": "VlfF4KPzRqwI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOcPJdzrHVHrZ1OgG5hZ/cP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/OpenAI/blob/main/SR_Whisper_tutorialoriginal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open AI {Whisper}\n",
        "\n",
        "* [Video tutorial](https://www.youtube.com/watch?v=Wc4bQxuypo0&t=210s)\n",
        "* [Online blog](https://openai.com/blog/whisper/)"
      ],
      "metadata": {
        "id": "2K0RUzO-2mjk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Set GPU in Runtime (colab menu-Runtime) \n",
        "2. Install the OpenAI Whisper Python package"
      ],
      "metadata": {
        "id": "9sO9ftiK3VW2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpdsG1JR2jdK"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking which GPU is being used in the current runtime\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "cevL3I-P3aT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we'll be using youtube video(audio), we import {pytube}"
      ],
      "metadata": {
        "id": "oPtTUefM4Zr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube -q"
      ],
      "metadata": {
        "id": "p7kancTA4SjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from pytube import YouTube"
      ],
      "metadata": {
        "id": "ePEfnTpC4X1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Whisper has a variety of models of varying sizes. The large model will be more accurate but will be more resource intensive.\"\n",
        "\n",
        "|Size|Parameters|English-only model|Multilingual model|\n",
        "|--|--|--|--|\n",
        "|tiny|39M|V|V|\n",
        "|base|74M|V|V|\n",
        "|small|244M|V|V|\n",
        "|medium|769M|V|V|\n",
        "|large|1550M|V|V|\n",
        "\n",
        "The base model will be sufficient for our needs."
      ],
      "metadata": {
        "id": "2D9dP8hg4tXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model('base')"
      ],
      "metadata": {
        "id": "QfOGmlqY4m7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_video_url = \"https://www.youtube.com/watch?v=NT2H9iyd-ms\"\n",
        "youtube_video = YouTube(youtube_video_url)"
      ],
      "metadata": {
        "id": "dvgnSl9T5mT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_video.title"
      ],
      "metadata": {
        "id": "3EnHS0Ni50zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Meta information in the video link\n",
        "dir(youtube_video)"
      ],
      "metadata": {
        "id": "jjoYr2rV54W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_video.streams"
      ],
      "metadata": {
        "id": "ZEmAxAfX5_Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be using the audio channel. Thus, we'll filter down to audio streams only. "
      ],
      "metadata": {
        "id": "oytDP3Rq6G0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for streams in youtube_video.streams:\n",
        "  print(streams)"
      ],
      "metadata": {
        "id": "Wj8F95-X6GYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering\n",
        "streams = youtube_video.streams.filter(only_audio=True)\n",
        "streams"
      ],
      "metadata": {
        "id": "Wsvo6pu76Vfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream = streams.first()\n",
        "stream"
      ],
      "metadata": {
        "id": "LrGC0jOr6pRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "???????? How do we know the audio file name?"
      ],
      "metadata": {
        "id": "iggqsjYB7ECt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stream.download(filename = 'fed_meeting.mp4')"
      ],
      "metadata": {
        "id": "EQELHPAv6v7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning process (single speaker)\n",
        "\n",
        "timeline 378~2715"
      ],
      "metadata": {
        "id": "jYWSi4hB7JXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -ss 378 -i fed_meeting.mp4 -t 2715 fed_meeting_trimmed.mp4"
      ],
      "metadata": {
        "id": "X0ACrKWa7DRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# save a timestamp before transcription\n",
        "t1 = datetime.datetime.now()\n",
        "print(f\"started at {t1}\")\n",
        "\n",
        "# do the transcription\n",
        "output = model.transcribe(\"fed_meeting_trimmed.mp4\")\n",
        "\n",
        "# show time elapsed after transcription is complete.\n",
        "t2 = datetime.datetime.now()\n",
        "print(f\"ended at {t2}\")\n",
        "print(f\"time elapsed: {t2 - t1}\")"
      ],
      "metadata": {
        "id": "jPizkayv7ea0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output itself is too big.\n",
        "# output\n",
        "output['text']"
      ],
      "metadata": {
        "id": "QUI9PdWR76_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for segment in output['segments']:\n",
        "  print(segment)\n",
        "  second = int(segment['start'])\n",
        "  second = second - (second % 5)\n",
        "  print(second)"
      ],
      "metadata": {
        "id": "DwUCKrFI8cWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining Speech Data with Price Data\n",
        "\n",
        "Now that we have this speech and the associated timestamps, we can go further by merging these segments into a dataframe containing price data. Let's see how the speech maps to the price of the S&P 500. I have retrieved 5 second OHLCV data for SPY using Interactive Brokers. A copy of this data and the code used to retrieve it are located on the website. We can upload spy.csv to Colab and process it using pandas."
      ],
      "metadata": {
        "id": "pleIt3La9OyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "data(spy.csv) to download - [file link](https://gist.githubusercontent.com/hackingthemarkets/c6ca7834d2af4932e3ab0d847679c14e/raw/b28fde61c41465565042d75fb2438adc9684d77b/spy.csv)"
      ],
      "metadata": {
        "id": "sN_0CBQ-916E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "spy = pd.read_csv(\"spy.csv\")"
      ],
      "metadata": {
        "id": "vMcqcRnA9QgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spy"
      ],
      "metadata": {
        "id": "WTWXvvbi-CwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for segment in output['segments']:\n",
        "   second = int(segment['start'])\n",
        "   second = second - (second % 5)\n",
        "   spy.loc[second / 5, 'text'] = segment['text']\n",
        "\n",
        "spy"
      ],
      "metadata": {
        "id": "lCla26ug-MxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spy['percent'] = ((spy['close'] - spy['open']) / spy['open']) * 100"
      ],
      "metadata": {
        "id": "fVa_U5EV-e3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_downmoves = spy[spy.percent < -0.2]\n",
        "big_downmoves"
      ],
      "metadata": {
        "id": "xq26ub7g-la2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the data on 14:36 using mplfinance:"
      ],
      "metadata": {
        "id": "dUJVL4oh-0Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mplfinance -q\n",
        "import mplfinance as mpf\n",
        "\n",
        "df = spy\n",
        "df.index = pd.DatetimeIndex(df['date'])\n",
        "\n",
        "mpf.plot(df['2022-11-02 14:36':'2022-11-02 14:39'],type='candle')"
      ],
      "metadata": {
        "id": "DErpBtxq-wHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spy[50:70]"
      ],
      "metadata": {
        "id": "BT1QW1Ps-7-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does this mean? Why are we doing this? \n",
        "\n",
        "=> This code has done what humans interprete while listening speech. AI extracted meaningful information from audio signal. Isn't it cool?"
      ],
      "metadata": {
        "id": "DIouwj6O_a3B"
      }
    }
  ]
}